# WEATHER-PREDICTION
Supercomputers must spend hours doing calculations for numerical weather forecasting on high-resolution physical models. Deep learning and machine learning techniques applied to forecasting lead to the discovery of novel solutions in this field. In this project, we propose a unique deep learning architecture to anticipate high-resolution numerical weather data utilizing both input weather data and observations. The issue is formulated as a spatiotemporal forecast. Convolutional Long-Short Term Memory and encoder-decoder-structured convolutional neural network units make up our model. With an attention and a context matcher mechanism, we improve the short- and long-term performance as well as interpretability. We conduct tests using the ERA5 hourly data on pressure levels, a high-scale, realistic, benchmark numerical weather dataset, and we forecast the temperature. The outcomes demonstrate notable progress in capturing both spatial and temporal correlations with attention matrices concentrating on various input series' components. Among the baseline models, such as the ConvLSTM forecasting network and U-Net, our model receives the best validation and test results. With the use of qualitative and quantitative data, we demonstrate how well our model predicts 10-time steps with a 3-hour frequency and an average error of 2 degrees.
Long short-term memory networks, or LSTMs, are employed in deep learning. Many recurrent neural networks (RNNs) are able to learn long-term dependencies, particularly in tasks involving sequence prediction. Aside from singular data points like photos, LSTM has feedback connections, making it capable of processing the complete sequence of data. This has uses in machine translation and speech recognition, among others. A unique version of RNN called LSTM exhibits exceptional performance on a wide range of issues. Using the real-time dataset, the suggested concept is examined.

Keywords â€“ Adaptive Resonance Theory (ART), Artificial intelligence, Artificial Neural Network (ANN), Back propagation algorithm, Feed forward, Fuzzy logic, Genetic algorithm, Multi-layer perceptron, Radial basis function (RBF), Supervised learning.
